{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb7911b",
   "metadata": {},
   "source": [
    "This is the code for the Machine Learning Model for the Vancouver Housing Affordability project.\n",
    "To do a basic test you can simply run all the cells in order. For more detailed testing instructions refer\n",
    "to the README file.\n",
    "\n",
    "Please note that this code requires two files \"ML-Model-Cleaned.csv\" and \"static_params.txt\" to be saved in the same folder, and won't work otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1935056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b373063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the initial data from the file.\n",
    "filename = \"ML-Model-Cleaned.csv\"\n",
    "data = pd.read_csv(filename).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8e7a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#CHANGABLE MODEL PARAMETERS\n",
    "#These are the only values in the notebook that should be\n",
    "#changed. Each time you change one of these you need to\n",
    "#re-run all the cells below in order (including re-training\n",
    "#the ML model) for the change to take effect.\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "#LOOKBACK_YEARS Parameter determines how many previous\n",
    "#of property values get included in each feature vector.\n",
    "#For example, if LOOKBACK_YEARS = 5 then the feature vector\n",
    "#for predicting 2025 prices will include property valeus\n",
    "#from 2020-2024. Should never be higher than 19. See\n",
    "#next parameter for additional restrictions.\n",
    "#Can be set to 0 to predict without using property values.\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "LOOKBACK_YEARS = 0\n",
    "\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "#TRAINING_YEARS parameter lists which years of data \n",
    "#data the model will try to predict as part of training.\n",
    "#For any given year, the model will try to predict every\n",
    "#property in that year (except those held out for testing).\n",
    "#Adding more years means more training data, but using\n",
    "#only 2024 is sufficient to get decent accuracy.\n",
    "#Only years in the range 2006-2024 should ever be used, but\n",
    "#if using the early end of the range, you need to also make\n",
    "#sure that you're not looking back beyond it. For example, if\n",
    "#LOOKBACK_YEARS = 5, then you can't train on any year earlier\n",
    "#than 2010 (since the 2009 df would try to incorporate 2005)\n",
    "#property values, which we don't have.\n",
    "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "TRAINING_YEARS = [2013, 2017, 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6ee0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOBAL CONSTANTS AND FILE INPUTS\n",
    "#This cell defines global constants plus a line that reads a file to\n",
    "#determine which 'static columns' (columns that don't depend on year)\n",
    "#to use. Needs to have correctly-named file in the same folder to run\n",
    "#without errors.\n",
    "\n",
    "\n",
    "LATEST_DATA_YEAR = 2024\n",
    "FIRST_DATA_YEAR = 2006\n",
    "IMPROVEMENT_PREFIX = \"CURRENT_IMPROVEMENT_VALUE_\"\n",
    "IMPROVEMENT_SUFFIX = \"_YEAR_AGO_IMPROVEMENT_VALUE\"\n",
    "LAND_PREFIX = \"CURRENT_LAND_VALUE_\"\n",
    "LAND_SUFFIX = \"_YEAR_AGO_LAND_VALUE\"\n",
    "OCCUPANCY_PREFIX = \"Count_Per_Year_\"\n",
    "Y_COLS = [\"IMPROVEMENT_VALUE\", \"LAND_VALUE\"]\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "f = open(\"static_params.txt\", \"r\") \n",
    "f_params = f.read() \n",
    "stat_cols = f_params.replace('\\n', ',').split(',')\n",
    "f.close()\n",
    "num_cols = len(stat_cols) - 1\n",
    "stat_cols = stat_cols[:num_cols] #remove empty string in last position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ad32e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DATA LOADING AND SHAPING FUNCTIONS\n",
    "#Function in this cell are used to filter and format the raw data\n",
    "#from the CSV file into the correct format and shape to be used\n",
    "#by the ML model.\n",
    "\n",
    "#Input a year (among the years we have data for) and selects all relevant\n",
    "#data for that year into a dataframe, altering the column names to a\n",
    "#consistent standard that doesn't depend on the year.\n",
    "#If you pass in a year that's too near the start (as determined by global)\n",
    "#constant LOOKBACK_YEARS, you'll get an error\n",
    "def get_year_data(pred_year):\n",
    "    year_cols = [] #generate column names for all the year-dependent stuff\n",
    "    new_col_names = {}\n",
    "    \n",
    "    #We need to change our column names from having absolute years (e.g. 2017)\n",
    "    #to relative years (7 years ago) so we make a dictionary relating the two\n",
    "    for year in range(pred_year - LOOKBACK_YEARS, pred_year):\n",
    "        imp, land = IMPROVEMENT_PREFIX + str(year), LAND_PREFIX + str(year)\n",
    "        year_cols += [imp, land]\n",
    "        new_col_names.update({imp:str(pred_year - year) + IMPROVEMENT_SUFFIX})\n",
    "        new_col_names.update({land:str(pred_year - year) + LAND_SUFFIX})\n",
    "    \n",
    "    #only save one year of occupancy data\n",
    "    occup = OCCUPANCY_PREFIX + str(pred_year - 1)\n",
    "    year_cols.append(occup)\n",
    "    new_col_names.update({occup:\"OCCUPANCY\"})\n",
    "    \n",
    "    #Most recent columns of property data get special names, since they are \n",
    "    #the \"current\" values and thus our training labels/prediction targets\n",
    "    X_cols = stat_cols + year_cols\n",
    "    yimp, yland = IMPROVEMENT_PREFIX + str(pred_year), LAND_PREFIX + str(pred_year)\n",
    "    y_cols_temp = [yimp, yland]\n",
    "    \n",
    "    #Copy the columns we want from the original df and then rename them\n",
    "    prepped_df = data[X_cols + y_cols_temp]\n",
    "    prepped_df.rename(columns = new_col_names, inplace=True)\n",
    "    prepped_df.rename(columns={yimp:Y_COLS[0], yland:Y_COLS[1]},inplace=True)\n",
    "    prepped_df.insert(0,'YEAR',pred_year)\n",
    "    \n",
    "    return prepped_df\n",
    "\n",
    "#Splits a prepped dataframe into training and testing sets\n",
    "#and into X and y components\n",
    "def split_data(df):\n",
    "    train, test = train_test_split(full_df,test_size=0.2)\n",
    "    y_train = train[Y_COLS]\n",
    "    y_test = test[Y_COLS]\n",
    "    X_train = train.drop(Y_COLS, axis=1)\n",
    "    X_test = test.drop(Y_COLS, axis=1)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "#Takes in a list of years, calls get_year_data for each\n",
    "#of those years and combines them\n",
    "def combine_years(years):\n",
    "    empty = True\n",
    "    for year in years:\n",
    "        if(empty):\n",
    "            df = get_year_data(year)\n",
    "            empty = False\n",
    "        else:\n",
    "            more_data = get_year_data(year)\n",
    "            df = pd.concat([df,more_data],axis=0)\n",
    "            \n",
    "    return df\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "890fe8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702466258940381\n"
     ]
    }
   ],
   "source": [
    "#TRAINING AND TESTING ML MODEL\n",
    "#This cell gathers the data to feed into the model\n",
    "#Calls the function to split it into train and test\n",
    "#sets and then trains and scores the model\n",
    "\n",
    "full_df = combine_years(TRAINING_YEARS)\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(full_df)\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "score = rf.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b70e244b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances for RandomForest Model:\n",
      "YEAR :  9.167693362389665 %\n",
      "YEAR_BUILT :  3.3330998698232777 %\n",
      "BIG_IMPROVEMENT_YEAR :  4.033745614464224 %\n",
      "LATITUDE :  7.520921399886735 %\n",
      "LONGITUDE :  9.285415735374668 %\n",
      "MIN_DISTANCE_LIBRARY_METERS :  3.5549344242262624 %\n",
      "COMMUNITY_CENTRE_DISTANCE_METERS :  2.938592770106727 %\n",
      "CLOSEST_DOG_PARK_METERS :  4.8479505374431415 %\n",
      "CLOSEST_HOMELESS_SHELTER :  3.162412281969572 %\n",
      "CLOSEST_PUBLIC_ART :  7.520654722122804 %\n",
      "CLOSEST_RAPID_TRANSIST :  4.906247847621237 %\n",
      "CLOSEST_BUS_STOPS :  5.4051228743948 %\n",
      "SCHOOL_DISTANCE :  3.9414346099109725 %\n",
      "PARK_DISTANCE :  4.0089614097981645 %\n",
      "PARK_AREA_HECTARES :  1.9891439557957036 %\n",
      "CULTURAL_SPACE_YEAR :  0.9148303240988701 %\n",
      "CULTURAL_SPACE_DISTANCE :  3.624197249054015 %\n",
      "OCCUPANCY :  19.84464101151916 %\n"
     ]
    }
   ],
   "source": [
    "#FEATURE IMPORTANCE\n",
    "#Displays feature importances in a readable form\n",
    "print(\"Feature Importances for RandomForest Model:\")\n",
    "for i in range(len(X_test.columns)):\n",
    "    print(X_test.columns[i], \": \", 100*rf.feature_importances_[i], \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c344bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS FOR PREDICTING FUTURE YEARS\n",
    "#The two function in this cell are used\n",
    "#to allow the model to make predictions on\n",
    "#future years\n",
    "\n",
    "#Takes in an X dataframe and a y numpy array and updates\n",
    "#the dataframe to include the new values, pushing out the\n",
    "#oldest year of data to make room\n",
    "#Seems to have some sort of error that causes some small\n",
    "#number of props not to be correctly updated and getting NAN \n",
    "#values instead. We didn't have time to chase down the\n",
    "#error, so it's patched by simply dropping the affected \n",
    "#rows in the predict_future_year rows function\n",
    "def update_prop_values(old_df, new_prop_data):\n",
    "    updata = old_df\n",
    "    \n",
    "    for i in range(LOOKBACK_YEARS - 1):\n",
    "        updata[str(LOOKBACK_YEARS-i) + IMPROVEMENT_SUFFIX]\\\n",
    "        = updata[str(LOOKBACK_YEARS-i-1) + IMPROVEMENT_SUFFIX]\n",
    "        \n",
    "        updata[str(LOOKBACK_YEARS-i) + LAND_SUFFIX]\\\n",
    "        = updata[str(LOOKBACK_YEARS-i-1) + LAND_SUFFIX]\n",
    "        \n",
    "    pred_df = pd.DataFrame(data=new_prop_data, columns=Y_COLS)\n",
    "    updata['1'+IMPROVEMENT_SUFFIX] = pred_df[Y_COLS[0]]\n",
    "    updata['1'+LAND_SUFFIX] = pred_df[Y_COLS[1]]\n",
    "    \n",
    "    return updata\n",
    "\n",
    "#Makes predictions for some future year. If the year is more\n",
    "#than one year in advance, it will recursively predict each\n",
    "#year between that year and 2024. Returns both the predictions\n",
    "#and the updata dataframe (the latter being necessary so it)\n",
    "#can feed it forward to predict further-future years\n",
    "def predict_future_year(model, year):\n",
    "    \n",
    "    #If we're predicting just one year in the future we can\n",
    "    #just use values from our existing dataframe\n",
    "    if(year == LATEST_DATA_YEAR + 1):\n",
    "        last_year = get_year_data(year-1)\n",
    "        prev_data = last_year.drop(Y_COLS, axis=1)\n",
    "        prev_predictions = last_year[Y_COLS]\n",
    "    \n",
    "    #If we're predicting farther in the future, we need to fill in all\n",
    "    #years between our latest data and the year we're predicting \n",
    "    elif(year > LATEST_DATA_YEAR + 1):\n",
    "        prev_data,prev_predictions  = predict_future_year(model,year-1)\n",
    "    \n",
    "    #Update property data (if necessary), advance the year and\n",
    "    #Make next year's predictions\n",
    "    if(LOOKBACK_YEARS > 0):\n",
    "        prev_data = update_prop_values(prev_data,prev_predictions)\n",
    "    prev_data['YEAR'] = prev_data['YEAR'].apply(lambda x: x+1)    \n",
    "    predictions = model.predict(prev_data.dropna())\n",
    "    \n",
    "    return prev_data, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09d6c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING THE MODEL AND MAKING PREDICTIONS\n",
    "#This is the cell where the model can actually be\n",
    "#used to predict future property values. You can\n",
    "#change future_prediction_year to any year after\n",
    "#2024 to predict future property values\n",
    "\n",
    "#To inspect the results in Jupyter Notebook,\n",
    "#uncomment one of the three lines at the end to \n",
    "#see either just the predictions, just the updated\n",
    "#dataframe or both together\n",
    "\n",
    "future_prediction_year = 2027\n",
    "\n",
    "updata, preds = predict_future_year(rf, future_prediction_year)\n",
    "pred_df = pd.DataFrame(data=preds, columns=Y_COLS)\n",
    "\n",
    "#pred_df\n",
    "#updata.dropna()\n",
    "#pd.concat([updata, pred_df], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199e6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
